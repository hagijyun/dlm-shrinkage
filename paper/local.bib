% This file was created with JabRef 2.9b2.
% Encoding: ISO8859_1

@ARTICLE{Balke1993,
  author = {Balke, Nathan S.},
  title = {Detecting Level Shifts in Time Series},
  year = {1993},
  language = {English},
  volume = {11},
  number = {1},
  pages = {pp. 81-92},
  issn = {07350015},
  url = {http://www.jstor.org/stable/1391308},
  abstract = {This article demonstrates the difficulty that traditional outlier
	detection methods, such as that of Tsay, have in identifying level
	shifts in time series. Initializing the outlier/level-shift search
	with an estimated autoregressive moving average model lowers the
	power of the level-shift detection statistics. Furthermore, the rule
	employed by these methods for distinguishing between level shifts
	and innovation outliers does not work well in the presence of level
	shifts. A simple modification to Tsay's procedure is proposed that
	improves the ability to correctly identify level shifts. This modification
	is relatively easy to implement and appears to be quite effective
	in practice.},
  copyright = {Copyright © 1993 American Statistical Association},
  journal = {Journal of Business \& Economic Statistics},
  jstor_articletype = {research-article},
  jstor_formatteddate = {Jan., 1993},
  owner = {jeff},
  publisher = {American Statistical Association},
  timestamp = {2013.04.22}
}

@ARTICLE{CalderiaZorn1998,
  author = {Calderia, Gregory A. and Zorn, Christopher J. W.},
  title = {Of Time and Consensual Norms in the Supreme Court},
  year = {1998},
  language = {English},
  volume = {42},
  number = {3},
  pages = {pp. 874-902},
  issn = {00925853},
  url = {http://www.jstor.org/stable/2991733},
  abstract = {Theory: We argue that levels of concurrence and dissent on the U.S.
	Supreme Court are functions of "consensual norms." These norms arise
	from, and are influenced by, the behaviors of the individual justices,
	including the actions of the chief justices. In turn, they cause
	concurrences and dissents to fluctuate around a common level. Hypotheses:
	If consensual norms are a substantial influence on the behavior of
	the Court, the long-run extent of concurrence and dissent on the
	Court will covary substantially, and will do so to varying degrees
	under different chief justices. Methods: To test our hypotheses,
	we use cointegration and error-correction analyses of the number
	of Supreme Court cases from 1800 to 1991 with concurring and dissenting
	opinions. Because of the dramatic increase in concurrences and dissents
	during the 1940s, we make use of recently-developed methods for detecting
	cointegrating relationships in the presence of structural breaks.
	Results: Consistent with our expectations, dissents and concurrences
	move together over time; thus consensual norms appear to influence
	substantially both concurrences and dissents on the Court. The effects
	of such norms vary in the long term under different Chief Justices.},
  copyright = {Copyright © 1998 Midwest Political Science Association},
  journal = {American Journal of Political Science},
  jstor_articletype = {research-article},
  jstor_formatteddate = {Jul., 1998},
  owner = {jrnold},
  publisher = {Midwest Political Science Association},
  timestamp = {2013.04.25}
}

@ARTICLE{CarterKohn1994,
  author = {Carter, C. K. And Kohn, R.},
  title = {On Gibbs sampling for state space models},
  year = {1994},
  volume = {81},
  number = {3},
  pages = {541-553},
  doi = {10.1093/biomet/81.3.541},
  eprint = {http://biomet.oxfordjournals.org/content/81/3/541.full.pdf+html},
  url = {http://biomet.oxfordjournals.org/content/81/3/541.abstract},
  abstract = {SUMMARY We show how to use the Gibbs sampler to carry out Bayesian
	inference on a linear state space model with errors that are a mixture
	of normals and coefficients that can switch over time. Our approach
	simultaneously generates the whole of the state vector given the
	mixture and coefficient indicator variables and simultaneously generates
	all the indicator variables conditional on the state vectors. The
	states are generated efficiently using the Kalman filter. We illustrate
	our approach by several examples and empirically compare its performance
	to another Gibbs sampler where the states are generated one at a
	time. The empirical results suggest that our approach is both practical
	to implement and dominates the Gibbs sampler that generates the states
	one at a time.},
  journal = {Biometrika},
  owner = {jeff},
  timestamp = {2013.05.28}
}

@ARTICLE{CarvalhoPolsonScott2010,
  author = {Carvalho, Carlos M. and Polson, Nicholas G. and Scott, James G.},
  title = {The horseshoe estimator for sparse signals},
  year = {2010},
  volume = {97},
  number = {2},
  pages = {465-480},
  doi = {10.1093/biomet/asq017},
  eprint = {http://biomet.oxfordjournals.org/content/97/2/465.full.pdf+html},
  url = {http://biomet.oxfordjournals.org/content/97/2/465.abstract},
  abstract = {This paper proposes a new approach to sparsity, called the horseshoe
	estimator, which arises from a prior based on multivariate-normal
	scale mixtures. We describe the estimator?s advantages over existing
	approaches, including its robustness, adaptivity to different sparsity
	patterns and analytical tractability. We prove two theorems: one
	that characterizes the horseshoe estimator?s tail robustness and
	the other that demonstrates a super-efficient rate of convergence
	to the correct estimate of the sampling density in sparse situations.
	Finally, using both real and simulated data, we show that the horseshoe
	estimator corresponds quite closely to the answers obtained by Bayesian
	model averaging under a point-mass mixture prior.},
  journal = {Biometrika},
  owner = {jrnold},
  timestamp = {2013.03.01}
}

@ARTICLE{CarvalhoPolsonScott2009,
  author = {Carlos M. Carvalho and Nicholas G. Polson and James G. Scott},
  title = {Handling Sparsity via the Horseshoe},
  journaltitle = {Journal of Machine Learning and Research: Workshop and Conference
	Proceedings},
  year = {2009},
  volume = {5},
  pages = {73-80},
  abstract = {This paper presents a general, fully Bayesian framework for sparse
	supervised-learning problems based on the horseshoe prior. The horseshoe
	prior is a member of the family of multivariate scale mixtures of
	normals, and is therefore closely related to widely used approaches
	for sparse Bayesian learning, including, among others, Laplacian
	priors (e.g. the LASSO) and Student-t priors (e.g. the relevance
	vector machine). The advantages of the horseshoe are its robustness
	at handling unknown sparsity and large outlying signals. These properties
	are justifed theoretically via a representation theorem and accompanied
	by comprehensive empirical experiments that compare its performance
	to benchmark alternatives.},
  owner = {jrnold},
  timestamp = {2013.03.01}
}

@ARTICLE{ChanJeliazkov2009,
  author = {Chan, Joshua C.C. and Jeliazkov, Ivan},
  title = {Efficient simulation and integrated likelihood estimation in state
	space models},
  year = {2009},
  volume = {1},
  number = {1},
  month = jan,
  pages = {101--120},
  url = {http://dx.doi.org/10.1504/IJMMNO.2009.03009},
  abstract = {We consider the problem of implementing simple and efficient Markov
	chain Monte Carlo (MCMC) estimation algorithms for state space models.
	A conceptually transparent derivation of the posterior distribution
	of the states is discussed, which also leads to an efficient simulation
	algorithm that is modular, scalable and widely applicable. We also
	discuss a simple approach for evaluating the integrated likelihood,
	defined as the density of the data given the parameters but marginal
	of the state vector. We show that this high-dimensional integral
	can be easily evaluated with minimal computational and conceptual
	difficulty. Two empirical applications in macroeconomics demonstrate
	that the methods are versatile and computationally undemanding. In
	one application, involving a time-varying parameter model, we show
	that the methods allow for efficient handling of large state vectors.
	In our second application, involving a dynamic factor model, we introduce
	a new blocking strategy which results in improved MCMC mixing at
	little cost. The results demonstrate that the framework is simple,
	flexible and efficient.},
  journal = {International Journal of Mathematical Modelling and Numerical Optimisation},
  owner = {jrnold},
  timestamp = {2013.05.27}
}

@ARTICLE{Cobb1978,
  author = {Cobb, George W.},
  title = {The problem of the Nile: Conditional solution to a changepoint problem},
  year = {1978},
  volume = {65},
  number = {2},
  pages = {243-251},
  doi = {10.1093/biomet/65.2.243},
  eprint = {http://biomet.oxfordjournals.org/content/65/2/243.full.pdf+html},
  url = {http://biomet.oxfordjournals.org/content/65/2/243.abstract},
  abstract = {Inference is considered for the point in a sequence of random variables
	at which the probability distribution changes. An approximation to
	the conditional distribution of the maximum likelihood estimator
	of the changepoint given the ancillary values of observations adjacent
	to the estimated changepoint is derived and shown to be numerically
	equal to a Bayesian posterior distribution for the changepoint. A
	hydrological example is given to show that inferences based on the
	conditional distribution of the maximum likelihood estimator can
	differ sharply from inferences based on the marginal distribution},
  journal = {Biometrika},
  owner = {jeff},
  timestamp = {2013.04.22}
}

@ARTICLE{CommandeurKoopmanOoms2011,
  author = {Jacques J. F. Commandeur and Siem Jan Koopman and Marius Ooms},
  title = {Statistical Software for State Space Methods},
  year = {2011},
  volume = {41},
  number = {1},
  month = {5},
  pages = {1--18},
  issn = {1548-7660},
  url = {http://www.jstatsoft.org/v41/i01},
  abstract = {In this paper we review the state space approach to time series analysis
	and establish the notation that is adopted in this special volume
	of the Journal of Statistical Software. We first provide some background
	on the history of state space methods for the analysis of time series.
	This is followed by a concise overview of linear Gaussian state space
	analysis including the modelling framework and appropriate estimation
	methods. We discuss the important class of unobserved component models
	which incorporate a trend, a seasonal, a cycle, and fixed explanatory
	and intervention variables for the univariate and multivariate analysis
	of time series. We continue the discussion by presenting methods
	for the computation of different estimates for the unobserved state
	vector: filtering, prediction, and smoothing. Estimation approaches
	for the other parameters in the model are also considered. Next,
	we discuss how the estimation procedures can be used for constructing
	confidence intervals, detecting outlier observations and structural
	breaks, and testing model assumptions of residual independence, homoscedasticity,
	and normality. We then show how ARIMA and ARIMA components models
	fit in the state space framework to time series analysis. We also
	provide a basic introduction for non-Gaussian state space models.
	Finally, we present an overview of the software tools currently available
	for the analysis of time series with state space methods as they
	are discussed in the other contributions to this special volume.},
  accepted = {2010-12-20},
  bibdate = {2010-12-20},
  coden = {JSSOBK},
  day = {12},
  journal = {Journal of Statistical Software},
  owner = {jrnold},
  submitted = {2009-08-22},
  timestamp = {2013.01.21}
}

@ARTICLE{DattaGhosh2012,
  author = {Jyotishka Datta and Jayanta. K. Ghosh},
  title = {Asymptotic Properties of Bayes Risk for the Horseshoe Prior},
  journaltitle = {Bayesian Analysis},
  year = {2012},
  volume = {7},
  issue = {4},
  pages = {771-792},
  owner = {jrnold},
  timestamp = {2013.03.01}
}

@ARTICLE{DeJongShephard1995,
  author = {{De Jong}, Piet and Shephard, Neil},
  title = {The simulation smoother for time series models},
  year = {1995},
  volume = {82},
  number = {2},
  pages = {339-350},
  doi = {10.1093/biomet/82.2.339},
  eprint = {http://biomet.oxfordjournals.org/content/82/2/339.full.pdf+html},
  url = {http://biomet.oxfordjournals.org/content/82/2/339.abstract},
  abstract = {Recently suggested procedures for simulating from the posterior density
	of states given a Gaussian state space time series are refined and
	extended. We introduce and study the simulation smoother, which draws
	from the multivariate posterior distribution of the disturbances
	of the model, so avoiding the degeneracies inherent in state samplers.
	The technique is important in Gibbs sampling with non-Gaussian time
	series models, and for performing Bayesian analysis of Gaussian time
	series.},
  journal = {Biometrika},
  owner = {jeff},
  timestamp = {2013.05.28}
}

@BOOK{DurbinKoopman2012,
  author = {Durbin, J. and Koopman, S.J.},
  title = {Time Series Analysis by State Space Methods: Second Edition},
  year = {2012},
  series = {Oxford Statistical Science Series},
  publisher = {OUP Oxford},
  isbn = {9780199641178},
  url = {http://books.google.com/books?id=fOq39Zh0olQC},
  lccn = {2011945385},
  owner = {jrnold},
  timestamp = {2013.04.22}
}

@BOOK{DurbinKoopman2001,
  author = {Durbin, J. and Koopman, S.S.J.},
  title = {Time Series Analysis by State Space Methods},
  year = {2001},
  series = {Oxford statistical sciences series},
  publisher = {Oxford University Press, Incorporated},
  isbn = {9780198523543},
  url = {http://books.google.com/books?id=XRCu5iSz\_HwC},
  lccn = {00054845},
  owner = {jeff},
  timestamp = {2013.04.22}
}

@ARTICLE{DurbinKoopman2002,
  author = {Durbin, J. and Koopman, S. J.},
  title = {A Simple and Efficient Simulation Smoother for State Space Time Series
	Analysis},
  year = {2002},
  language = {English},
  volume = {89},
  number = {3},
  pages = {pp. 603-615},
  issn = {00063444},
  url = {http://www.jstor.org/stable/4140605},
  abstract = {A simulation smoother in state space time series analysis is a procedure
	for drawing samples from the conditional distribution of state or
	disturbance vectors given the observations. We present a new technique
	for this which is both simple and computationally efficient. The
	treatment includes models with diffuse initial conditions and regression
	effects. Computational comparisons are made with the previous standard
	method. Two applications are provided to illustrate the use of the
	simulation smoother for Gibbs sampling for Bayesian inference and
	importance sampling for classical inference.},
  copyright = {Copyright © 2002 Biometrika Trust},
  journal = {Biometrika},
  jstor_articletype = {research-article},
  jstor_formatteddate = {Sep., 2002},
  owner = {jeff},
  publisher = {Biometrika Trust},
  timestamp = {2013.05.23}
}

@ARTICLE{Fruehwirth-Schnatter1994,
  author = {Fr\"uhwirth-Schnatter, Sylvia},
  title = {Data Augmentation And Dynamic Linear Models},
  journaltitle = {Journal of Time Series Analysis},
  year = {1994},
  volume = {15},
  number = {2},
  pages = {183--202},
  issn = {1467-9892},
  doi = {10.1111/j.1467-9892.1994.tb00184.x},
  url = {http://dx.doi.org/10.1111/j.1467-9892.1994.tb00184.x},
  abstract = {Abstract. We define a subclass of dynamic linear models with unknown
	hyperpara-meter called d-inverse-gamma models. We then approximate
	the marginal probability density functions of the hyperparameter
	and the state vector by the data augmentation algorithm of Tanner
	and Wong. We prove that the regularity conditions for convergence
	hold. For practical implementation a forward-filtering-backward-sampling
	algorithm is suggested, and the relation to Gibbs sampling is discussed
	in detail.},
  journal = {Journal of Time Series Analysis},
  keywords = {Approximate Bayesian analysis, data augmentation, dynamic linear models,
	Gibbs sampling, Kalman filtering, state space models},
  owner = {jeff},
  publisher = {Blackwell Publishing Ltd},
  timestamp = {2013.05.28}
}

@ARTICLE{GiordaniKohn2008,
  author = {Giordani, Paolo and Kohn, Robert},
  title = {Efficient Bayesian Inference for Multiple Change-Point and Mixture
	Innovation Models},
  year = {2008},
  volume = {26},
  number = {1},
  pages = {66-77},
  doi = {10.1198/073500107000000241},
  eprint = {http://amstat.tandfonline.com/doi/pdf/10.1198/073500107000000241},
  url = {http://amstat.tandfonline.com/doi/abs/10.1198/073500107000000241},
  abstract = { Time series subject to parameter shifts of random magnitude and timing
	are commonly modeled with a change-point approach using Chib's algorithm
	to draw the break dates. We outline some advantages of an alternative
	approach in which breaks come through mixture distributions in state
	innovations, and for which the sampler of Gerlach, Carter, and Kohn
	allows reliable and efficient inference. We show how the same sampler
	can be used to model shifts in variance that occur independently
	of shifts in other parameters and how to draw the break dates efficiently
	when regime durations follow a Poisson process. Finally, we introduce
	to the time series literature the concept of adaptive MetropolisâHastings
	sampling for discrete latent variable models. We develop an easily
	implemented adaptive algorithm that improves on the work of Gerlach
	et al. and promises to significantly reduce computing time in a variety
	of problems including mixture innovation, change-point, regime switching,
	and outlier detection. The efficiency gains on two models for U.S.
	inflation and real interest rates are 257% and 341%. },
  journal = {Journal of Business \& Economic Statistics},
  owner = {jeff},
  timestamp = {2013.04.22}
}

@ARTICLE{HarveyKoopman2000,
  author = {Harvey, Andrew and Koopman, Siem Jan},
  title = {Signal extraction and the formulation of unobserved components models},
  year = {2000},
  volume = {3},
  number = {1},
  pages = {84--107},
  issn = {1368-423X},
  doi = {10.1111/1368-423X.00040},
  url = {http://dx.doi.org/10.1111/1368-423X.00040},
  abstract = {This paper looks at unobserved components models and examines the
	implied weighting patterns for signal extraction. There are four
	main themes. The first concerns the implications of correlated disturbances
	driving the components, especially those cases in which the correlation
	is perfect. The second is about the way in which ARIMA-based methods
	for trend extraction relate to those based on unobserved components.
	The third explores the impact of heteroscedasticity and irregular
	spacing and shows how setting up models with t-distributed disturbances
	leads to weighting patterns which are robust to outliers and breaks.
	Finally, a comparison is made between implied weighting patterns
	with kernels used in non-parametric trend estimation and equivalent
	kernels used in spline smoothing. It is demonstrated that with irregularly
	spaced data, the weighting used by conventional spline smoothing
	techniques is not the same as that obtained from the time series
	model based approach.},
  journal = {Econometrics Journal},
  keywords = {Cubic splines, Kalman filter and smoother, Kernels, Robustness, Structural
	time series model, Trend, WienerâKolmogorov filter.},
  owner = {jeff},
  publisher = {Blackwell Publishers Ltd},
  timestamp = {2013.04.22}
}

@ARTICLE{HoffmanGelman2013,
  author = {Matthew D. Hoffman and Andrew Gelman},
  title = {The No-{U}-Turn Sampler: Adaptively Setting Path Lengths in {H}amiltonian
	{M}onte {C}arlo},
  year = {In press},
  journal = {Journal of Machine Learning Research},
  owner = {jrnold},
  timestamp = {2013.02.06}
}

@BOOK{Jackman2009,
  author = {Jackman, S.},
  title = {Bayesian Analysis for the Social Sciences},
  year = {2009},
  series = {Wiley Series in Probability and Statistics},
  publisher = {Wiley},
  isbn = {9780470686638},
  url = {http://books.google.com/books?id=QFqyrNL8yEkC},
  owner = {jrnold}
}

@ARTICLE{JongPenzer1998,
  author = {Jong, Piet de and Penzer, Jeremy},
  title = {Diagnosing Shocks in Time Series},
  year = {1998},
  language = {English},
  volume = {93},
  number = {442},
  pages = {pp. 796-806},
  issn = {01621459},
  url = {http://www.jstor.org/stable/2670129},
  abstract = {Efficient means of modeling aberrant behavior in times series are
	developed. Our methods are based on state-space forms and allow test
	statistics for various interventions to be computed from a single
	run of the Kalman filter smoother. The approach encompasses existing
	detection methodologies. Departures commonly observed in practice,
	such as outlying values, level shifts, and switches, are readily
	dealt with. New diagnostic statistics are proposed. Implications
	for structural models, autoregressive integrated moving average models,
	and models with explanatory variables are given.},
  copyright = {Copyright © 1998 American Statistical Association},
  journal = {Journal of the American Statistical Association},
  jstor_articletype = {research-article},
  jstor_formatteddate = {Jun., 1998},
  owner = {jrnold},
  publisher = {American Statistical Association},
  timestamp = {2013.05.02}
}

@ARTICLE{Park2011,
  author = {Park, Jong Hee},
  title = {Changepoint Analysis of Binary and Ordinal Probit Models: An Application
	to Bank Rate Policy Under the Interwar Gold Standard},
  year = {2011},
  doi = {10.1093/pan/mpr007},
  eprint = {http://pan.oxfordjournals.org/content/early/2011/03/22/pan.mpr007.full.pdf+html},
  url = {http://pan.oxfordjournals.org/content/early/2011/03/22/pan.mpr007.abstract},
  abstract = {In this paper, I introduce changepoint models for binary and ordered
	time series data based on Chib's hidden Markov model. The extension
	of the changepoint model to a binary probit model is straightforward
	in a Bayesian setting. However, detecting parameter breaks from ordered
	regression models is difficult because ordered time series data often
	have clustering along the break points. To address this issue, I
	propose an estimation method that uses the linear regression likelihood
	function for the sampling of hidden states of the ordinal probit
	changepoint model. The marginal likelihood method is used to detect
	the number of hidden regimes. I evaluate the performance of the introduced
	methods using simulated data and apply the ordinal probit changepoint
	model to the study of Eichengreen, Watson, and Grossman on violations
	of the ârules of the gameâ of the gold standard by the Bank of
	England during the interwar period.},
  journal = {Political Analysis},
  owner = {jrnold}
}

@ARTICLE{Park2010,
  author = {Park, Jong Hee},
  title = {Structural Change in U.S. Presidents' Use of Force},
  year = {2010},
  volume = {54},
  number = {3},
  pages = {766--782},
  issn = {1540-5907},
  doi = {10.1111/j.1540-5907.2010.00459.x},
  url = {http://dx.doi.org/10.1111/j.1540-5907.2010.00459.x},
  abstract = {Has there been a structural change in the way U.S. presidents use
	force abroad since the nineteenth century? In this article, I investigate
	historical changes in the use of force by U.S. presidents using Bayesian
	changepoint analysis. In doing so, I present an integrated Bayesian
	approach for analyzing changepoint problems in a Poisson regression
	model. To find the nature of the breaks, I estimate parameters of
	the Poisson regression changepoint model using Chib's (1998) hidden
	Markov model algorithm and FrÃ¼hwirth-Schnatter and Wagner's (2006)
	data augmentation method. Then, I utilize transdimensional Markov
	chain Monte Carlo methods to detect the number of breaks. Analyzing
	yearly use of force data from 1890 to 1995, I find that, controlling
	for the effects of the Great Depression and the two world wars, the
	relationship between domestic conditions and the frequency of the
	use of force abroad fundamentally shifted in the 1940s.},
  journal = {American Journal of Political Science},
  owner = {jrnold},
  publisher = {Blackwell Publishing Inc}
}

@BOOK{PetrisPetroneEtAl2009,
  author = {Petris, G. and Petrone, S. and Campagnoli, P.},
  title = {{Dynamic Linear Models with R}},
  year = {2009},
  series = {Use R!},
  publisher = {Springer},
  isbn = {9780387772370},
  url = {http://books.google.com/books?id=VCt3zVq8TO8C},
  file = {PetrisPetroneEtAl2009.pdf:PetrisPetroneEtAl2009.pdf:PDF},
  lccn = {2009926480},
  owner = {jrnold},
  timestamp = {2010.11.10}
}

@ARTICLE{PolsonScott2012,
  author = {Nicholas G. Polson and James G. Scott},
  title = {On the Half-Cauchy Prior for a Global Scale Parameter},
  journaltitle = {Bayesian Analysis},
  year = {2012},
  volume = {7},
  issue = {4},
  pages = {887-902},
  doi = {0.1214/12-BA730},
  abstract = {This paper argues that the half-Cauchy distribution should replace
	the inverse-Gamma distribution as a default prior for a top-level
	scale parameter in Bayesian hierarchical models, at least for cases
	where a proper prior is necessary. Our arguments involve a blend
	of Bayesian and frequentist reasoning, and are intended to complement
	the case made by Gelman (2006) in support of folded-t priors. First,
	we generalize the half-Cauchy prior to the wider class of hypergeometric
	inverted-beta priors. We derive expressions for posterior moments
	and marginal densities when these priors are used for a top-level
	normal variance in a Bayesian hierarchical model. We go on to prove
	a proposition that, together with the results for moments and marginals,
	allows us to characterize the frequentist risk of the Bayes estimators
	under all global-shrinkage priors in the class. These results, in
	turn, allow us to study the frequentist properties of the half-Cauchy
	prior versus a wide class of alternatives. The half-Cauchy occupies
	a sensible middle ground within this class: it performs well near
	the origin, but does not lead to drastic compromises in other parts
	of the parameter space. This provides an alternative, classical justication
	for the routine use of this prior. We also consider situations where
	the underlying mean vector is sparse, where we argue that the usual
	conjugate choice of an inverse-gamma prior is particularly inappropriate,
	and can severely distort inference. Finally, we summarize some open
	issues in the specication of default priors for scale terms in hierarchical
	models},
  keywords = {hierarchical models; normal scale mixtures; shrinkage},
  owner = {jrnold},
  timestamp = {2013.03.01}
}

@ARTICLE{PolsonScott2010,
  author = {Nicholas G. Polson and James G. Scott},
  title = {Shrink Globally, Act Locally: Sparse Bayesian Regularization and
	Prediction},
  journaltitle = {Bayesian Statistics},
  year = {2010},
  abstract = {We use Levy processes to generate joint prior distributions for a
	location parameter ? = (?1 , . . . , ?p ) as p grows large. This
	approach, which generalizes normal scale-mixture priors to an infinite-dimensional
	setting, has a number of connections with mathematical finance and
	Bayesian nonparametrics. We argue that it provides an intuitive framework
	for generating new regularization penalties and shrinkage rules;
	for performing asymptotic analysis on existing models; and for simplifying
	proofs of some classic results on normal scale mixtures.},
  owner = {jrnold},
  timestamp = {2013.03.01}
}

@ARTICLE{RatkovicEng2010,
  author = {Ratkovic, Marc T. and Eng, Kevin H.},
  title = {Finding Jumps in Otherwise Smooth Curves: Identifying Critical Events
	in Political Processes},
  year = {2010},
  volume = {18},
  number = {1},
  pages = {57-77},
  doi = {10.1093/pan/mpp032},
  eprint = {http://pan.oxfordjournals.org/content/18/1/57.full.pdf+html},
  url = {http://pan.oxfordjournals.org/content/18/1/57.abstract},
  abstract = {Many social processes are stable and smooth in general, with discrete
	jumps. We develop a sequential segmentation spline method that can
	identify both the location and the number of discontinuities in a
	series of observations with a time component, while fitting a smooth
	spline between jumps, using a modified Bayesian Information Criterion
	statistic as a stopping rule. We explore the method in a large-n,
	unbalanced panel setting with George W. Bush's approval data, a small-n
	time series with median DW-NOMINATE scores for each Congress over
	time, and a series of simulations. We compare the method to several
	extant smoothers, and the method performs favorably in terms of visual
	inspection, residual properties, and event detection. Finally, we
	discuss extensions of the method.},
  journal = {Political Analysis},
  owner = {jrnold},
  timestamp = {2013.03.01}
}

@UNPUBLISHED{Spirling2007,
  author = {Arthur Spirling},
  title = {Rebels with a Cause: Legislative Acitivity and the Personal Vote
	in Britian, 1997-2005},
  year = {2007},
  month = {11 August},
  abstract = {does a member of the british parliament's voting record have any effect
	on their constituency electoral performance? scholars have assumed
	not, else they have tested the proposition with an extremely limited
	number of roll calls. congruent with public opinion findings we contend
	that, paradoxically, voters conditionally reward both `party unity'
	and `independent minded- ness' in their elected representatives.
	using novel non-parametric `random forest' classification procedures,
	and a new data set recording behavior on over 2000 roll calls from
	1997-2001 and 2001-2005, along with commensurate constituency controls,
	we thus show that mps' popular- ity is indeed effected by their legislative
	activity in small but significant ways. in particular, government-party
	voters demand unity on votes that are key parts of the government's
	pro- grammatic agenda, while welcoming more `maverick' behavior on
	less important issues.},
  keywords = {Westminster systems, accountability, representation, political methodology},
  owner = {jrnold},
  tags = {URJob},
  timestamp = {2007.09.06}
}

@ARTICLE{Spirling2007a,
  author = {Spirling, Arthur},
  title = {"Turning Points" in the Iraq Conflict},
  year = {2007},
  volume = {61},
  number = {4},
  pages = {315-320},
  doi = {10.1198/000313007X247076},
  eprint = {http://pubs.amstat.org/doi/pdf/10.1198/000313007X247076},
  url = {http://pubs.amstat.org/doi/abs/10.1198/000313007X247076},
  abstract = { We consider and explore structural breaks in a day-by-day time series
	of civilian casualties for the current Iraq conflict: an undertaking
	of potential interest to scholars of international relations, comparative
	politics, and American politics. We review Bayesian change-point
	techniques already used by political methodologists before advocating
	and briefly describing the use of reversible-jump Markov chain Monte
	Carlo techniques to solve the estimation problem at hand. We find
	evidence of four change points, all associated with increasing violence,
	approximately contemporaneous with some important state building
	events. We conclude with a discussion of avenues for future research.
	},
  journal = {The American Statistician},
  owner = {jrnold},
  timestamp = {2010.10.12}
}

@ARTICLE{spirling2007bayesian,
  author = {Spirling, Arthur},
  title = {Bayesian Approaches for Limited Dependent Variable Change Point Problems},
  year = {2007},
  volume = {15},
  number = {4},
  pages = {387-405},
  doi = {10.1093/pan/mpm022},
  eprint = {http://pan.oxfordjournals.org/content/15/4/387.full.pdf+html},
  url = {http://pan.oxfordjournals.org/content/15/4/387.abstract},
  abstract = {Limited dependent variable (LDV) data are common in political science,
	and political methodologists have given much good advice on dealing
	with them. We review some methods for LDV âchange point problemsâ
	and demonstrate the use of Bayesian approaches for count, binary,
	and duration-type data. Our applications are drawn from American
	politics, Comparative politics, and International Political Economy.
	We discuss the tradeoffs both philosophically and computationally.
	We conclude with possibilities for multiple change point work.},
  journal = {Political Analysis},
  owner = {jrnold},
  timestamp = {2011-04-02}
}

@ARTICLE{Stan2013,
  author = {{Stan Development Team}},
  title = {Stan: A C++ Library for Probability and Sampling, Version 1.1},
  year = {2013},
  url = {http://mc-stan.org/},
  owner = {jrnold},
  timestamp = {2013.02.06}
}

@ARTICLE{StricklandTurnerDenhamEtAl2009,
  author = {Chris M. Strickland and Ian. W. Turner and Robert Denham and Kerrie
	L. Mengersen},
  title = {Efficient Bayesian estimation of multivariate state space models
	},
  year = {2009},
  volume = {53},
  number = {12},
  pages = {4116 - 4125},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2009.04.019},
  url = {http://www.sciencedirect.com/science/article/pii/S0167947309001698},
  abstract = {A Bayesian Markov chain Monte Carlo methodology is developed for the
	estimation of multivariate linear Gaussian state space models. In
	particular, an efficient simulation smoothing algorithm is proposed
	that makes use of the univariate representation of the state space
	model. Substantial gains over existing algorithms in computational
	efficiency are achieved using the new simulation smoother for the
	analysis of high dimensional multivariate time series. The methodology
	is used to analyse a multivariate time series dataset of the Normalised
	Difference Vegetation Index (NDVI), which is a proxy for the level
	of live vegetation, for a particular grazing property located in
	Queensland, Australia. },
  journal = {Computational Statistics \& Data Analysis },
  owner = {jeff},
  timestamp = {2013.05.23}
}

@BOOK{WestHarrison1997,
  author = {West, M. and Harrison, J.},
  title = {{Bayesian forecasting and dynamic models}},
  year = {1997},
  series = {Springer series in statistics},
  publisher = {Springer},
  isbn = {9780387947259},
  url = {http://books.google.com/books?id=jcl8lD75fkYC},
  file = {west1997bayesian.pdf:west1997bayesian.pdf:PDF},
  lccn = {96038166},
  owner = {jrnold},
  timestamp = {2010.11.19}
}

