\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[margin=1in]{geometry}

\usepackage[style=authoryear]{biblatex}

\bibliography{local}

\usepackage{setspace}
\doublespace

\author{Jeffrey B. Arnold}
\title{Time Varying Parameter Estimation Robust to Structural Breaks}

\begin{document}

\maketitle{}

When modeling time-varying parameters, there exist two approaches. 
The first approach is change-point or structural break models. 
In these models, the change in the parameter only occur at a few points and is contant otherwise.
In other words, the parameter is modeled with step function.
The second approach is time-varying parameter models in which the parameter changes in all periods.
This approach includes dynamic linear models and smoothing splines.

However, both structural break and time-varying parameters model can be modeled with dynamic linear models.
The difference between these approaches is in the distributions of the \textit{innovations}, the changes in the parameter values.
In structural break models, the innovations have a spike and slab distribution, which is a discrete mixture between 0 and another, usually diffuse, distribution.
In time-varying parameter models, the innovations are given a continuous distribution, usually the normal.

This paper proposes using scale mixture of normal distributions for the innovation distributions in order to nest both structural break and time varying parameter models.
The insight is that the problem posed in estimating time-varying parameters shares many characteristics with the ``large-p'' literature.
In the case of the a univariate time-series with $n$ obserservations and a time-varying mean, the number of innovation parameters to be estimated is $n - 1$.

There are two key features in parameter change in change-point models that the distribution of the innovations must capture.
\begin{enumerate}
\item \textit{sparsity}: Most innovations are expected to be approximately zero.
\item \textit{large signals}: Some innovations can be very large
\end{enumerate}
This means that a distribution over the innovations must both shrink small distributions to zero in order to ignore ``noise'', while not shrinking the large ``true'' innovations.
However, this is a similar problem to that in the $n > p$ literature, in which there has been a large amount of attention recently, e.g. the lasso.
Conveniently, many of the proposed shrinkage prior distributions are scale mixtures of normal distributions.

There are several reasons to use continuous distributions to model time-varying parameters possibly with structural breaks.
In the case of truly sparse data, discrete mixtures are computationally inefficient. 
And in the case of non-sparse change-points, the discrete mixture is unnecessary.

Change-point models are appealing because the change-points are often easy to substantively interpret, as they can be tied to events.
Change-point models are problematic because they either require that the researcher specify the number of change-points, and methods to estimate the number of change-points are not straight-forward.
Another issue with change-point models is how they perform when the model is wrong; i.e. what if there are no change-points but a time-varying parameter.

\section{Sparse Dynamic Linear Model}

Consider a simple local level model in which the mean of $y_{t}$ changes over time,
\begin{align}
  \label{eq:8}
  y_t &= \alpha_t + \epsilon_t & \epsilon_{t}  \\
  \label{eq:14}
  \alpha_t &= \alpha_{t-1} + \eta_{t} \\
  \label{eq:15}
  \epsilon_{t} & \sim N(0, \sigma^{2})
\end{align}
The innovations $\eta_{t}$ are distributed with the horseshoe distribution, introduced in Carvalho et al.
The horseshoe distribution does not have an analytical form, but is a scale-mixture of normal distributions,
\begin{align}
  \label{eq:12}
  \eta_{t} &\sim N(0, \lambda_{t}^{2} \tau^{2}) \\
  \label{eq:13}
  \lambda_{t} &\sim C^{+}(0, 1)
\end{align}

I assume the following non-informative hyper-priors on $\sigma^{2}$ and $\tau$ in Carvalho et al. (2010, 2009),
\begin{align}
  \label{eq:9}
  p(\sigma^{2}) & \frac{1}{\sigma^{2}}  \\
  \label{eq:11}
  \tau &\sim C^{+}(0, \sigma) \text{.}
\end{align}

\section{Innovation Selection and Shrinkage}
\label{sec:time-vary-param}

Consider a simple local level model in which the mean of $y_{t}$ changes over time,
\begin{equation}
  \label{eq:16}
  \begin{aligned}
    y_t &= \alpha_t + \epsilon_t \\
    \alpha_t &= \alpha_{t-1} + \eta_{t}
  \end{aligned}
\end{equation}
where $\epsilon_{t} \sim N(0, \sigma_{t}^{2})$ and $\eta_{t} \sim N(0, q_{t}^{2})$.
This is a special case of a normal dynamic linear models (DLM) \parencites{WestHarrison1997}{DurbinKoopman2012}{CommandeurKoopman2007}{ShumwayStoffer2010}.
DLMs are flexible class of models that include linear regressions and ARIMA models.
Moreover for the case in which $\epsilon_{t}$ and $\eta_{t}$ are distributed normal, there are computationally efficient methods both to maximize the likelihood of (Kalman Filter) and to sample from (Forward-filter backward sample) \eqref{eq:8}.

Commonly, $\eta_{t}$ are distributed i.i.d. normal,
\begin{equation}
  \label{eq:2}
  \eta_{t} \sim N(0, \tau^{2})
\end{equation}
Since the normal distribution has thin tails, \eqref{eq:2} smooths changes in $\alpha$ over time by penalizing large values of $\alpha_{t} - \alpha_{t-1}$.
Moreover, this means that $\alpha_{t} - \alpha_{t-1} \neq 0$ with certainty.
This is useful for modeling parameters which vary slowly over time.
However, many political processes are marked by sudden changes over time.

A structural break or change-point model can be represented in \eqref{eq:8} if $\eta$ is given a spike-and-slab mixture distribution \parencite{GiordaniKohn2008},
\begin{equation}
  \label{eq:1}
  \eta_{t} \sim p N(0, \tau^{2}) + (1 - p) \delta_{0} \text{,}
\end{equation}
where $p$ is the prior probability of a change, and $N(0, \tau^{2})$ is the distribution of the change in $\alpha$ if there is a structural break.

% Structural breaks
% There are several reasons why structural break methods are used.
% The first is that the underlying data generating processes in political processes is often marked by large shifts.
% The second is that stuctural breaks are easy to intrepret substantively.
% The output of the methods provides a small number of breaks which can be interpreted with respect to the events occuring contemporaneously.
% the key aspect of the a change point model is the sparsity in $\eta$.

An alternative approach is to model $\nu$ with a continuous distribution, that shrinks the estimates of $\nu$ such that they behave similar to a discrete mixture.
A alternative approach is to model $\omega$ with a scale mixture of normal distributions.
\begin{equation}
  \label{eq:6}
  \begin{aligned}[t]
    \eta_{t} | \tau^{2}, \lambda^{2} & \sim N(0, \tau^{2} \lambda_{t}^{2}) \\
    \lambda_{t}^{2} & \sim p(\lambda^{2}_{t})
  \end{aligned}
\end{equation}
where $\tau^{2}$ is a global shrinkage parameter, and $\lambda_{t}^{2}$ are global shrinkage parameters.
Many Bayesian shrinkage priors can be expressed in this form. 
The class of scale-normal mixtures includes many Bayesian shrinkage priors, such as the student-\textit{t} (Tipping), double-exponential prior (Bayesian LASSO) (Park  and Casella 2008), normal-Jeffreys (Figueiredo 2003, Bae and Mallick 2004), Strawderman-Berger (Stawderman 1971, Berger 1980), and normal-exponential-gamma (Griffin and Grown, 2005).
The $t$-distribution has suggested for dynamic linear model estimation that is robust to structural breaks \parencites{HarveyKoopman2000}{PetrisPetroneEtAl2009}. 
This paper will make use of the horseshoe distribution 

The Horseshoe distribution has several characteristics which make it particularly appealing for this application.
Under the discrete mixture model in equation \eqref{eq:1}, the expected value of the posterior distribution of $\eta_{t}$ if $\tau^{2}$ is large is approximately $w_{i} (y_{t} - \alpha_{t-1}$ i
\begin{equation}
  \label{eq:18}
  
\end{equation}

\begin{equation}
  \label{eq:17}
  
\end{equation}


Consider
Let $\Delta \alpha_{t} = \alpha_{t} - \alpha_{t - 1}$
\begin{equation}
  \label{eq:10}
  E(\Delta \alpha_{t} | \alpha_{t - 1}, \sigma, \tau, \lambda_{t}) = (y_{t} - \alpha_{t - 1})
  \left(
    1 - \frac{\sigma^{2}}{\sigma^{2} + \lambda^{2}_{t} \tau^{2}}
  \right)
\end{equation}
Let $\kappa_{t}$ be a shrinkage parameter, defined as
\begin{equation}
  \label{eq:3}
  \kappa_{t} = \frac{\sigma^{2}}{\sigma^{2} + \lambda^{2}_{t} \tau^{2}} \text{.}
\end{equation}
When $\kappa_{t} \approx 0$, the change in $\alpha$ is approximately $y_{t} - \alpha_{t-1}$.
When $\kappa_{t} \approx 1$, the change in $\alpha \approx 0$.

Interestingly, for the horseshoe prior distribution, the value $1 - \hat\kappa_{t}$, where $\hat\kappa_{t} = E(\kappa_{t})$, acts approximately like the posterior inclusion probability from a discrete mixture model (Carvallho et al).
Thus, Carvallho \textit{et al.} recommend the following  decision rule under a 0-1 decision rule as to whether an observation is a signal,
\begin{equation}
  \label{eq:5}
  \text{$H_{0,t}$ if $\nu_{t} = 1 - E(\kappa_{t}|y_{t}, \nu_{t-1} \lambda_{t}, \tau, \sigma) > \frac{1}{2}$}
\end{equation}


\section{Examples}
\label{sec:examples}

\subsection{Nile Flow Data}
\label{sec:nile}

The first example of change-point detection is a classic datset in the state-space and change point literature, the Nile river flow data \textcite{Cobb1978}{Balke1993}{DurbinKoopman2012}
The data consist of annual observations of the flow of the Nile river at Ashwan between 1871 and 1970. 
It is well known that there was a level shift in 1899, both due to the construction of a damn at Ashwan and weather changes.

\subsection{Greenbacks}
\label{sec:greenbacks-graybacks}

\subsection{Election}
\label{sec:election}

\textcite{RatkovicEng2010}.

\printbibliography{}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

%  LocalWords:  Carvallho
