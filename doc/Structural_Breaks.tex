\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[margin=1in]{geometry}

\usepackage[style=authoryear]{biblatex}

\bibliography{local}

\usepackage{setspace}
\doublespace

\author{Jeffrey B. Arnold}
\title{Time Varying Parameter Estimation Robust to Structural Breaks}

\begin{document}

\maketitle{}

When modeling time-varying parameters, researchers in political science have generally had to choose between two approaches. 
The first is with change-point or structural breaks models, in which the changes in the parameter only occur in a few points, and the parameter is constant within those regions.
The second is with time-varying parameter models in which the parameter changes in each period, but its changes are shrunk so that the change over time is smoothed.

This paper makes two contributions.
The first is that (some) structural break and time-varying parameters models are both cases of dynamic linear models, which differ in their assumptions on the distribution of the changes in the parameter (``innovations'').
Structural break models assume innovations are drawn from a spike and slab distribution, i.e. a discrete mixture between 0 and another, usually diffuse, distribution.
Time-varying parameter models assume a continuous, usually normal, distribution on the innovations.

The second contribution is that structural breaks can be modeled without a spike and slab distribution, by using scale mixtures of normal distributions.
There are two key features in parameter change in change-point models that the distribution of the innovation must capture.
\begin{enumerate}
\item \textit{sparsity}: Most innovations are expected to be approximately zero.
\item \textit{large signals}: Some innovations can be very large
\end{enumerate}
This means that a distribution over the innovations must both shrink small distributions to zero in order to ignore ``noise'', while not shrinking the large ``true'' innovations.
However, this is a similar problem to that in the $n > p$ literature, in which there has been a large amount of attention recently, e.g. the lasso.
Conveniently, many of the proposed shrinkage prior distributions are scale mixtures of normal distributions.

Change-point models are appealing because the change-points are often easy to substantively interpret, as they can be tied to events.
Change-point models are problematic because they either require that the researcher specify the number of change-points, and methods to estimate the number of change-points are not straight-forward.
Another issue with change-point models is how they perform when the model is wrong; i.e. what if there are no change-points but a time-varying parameter.

This paper proposes a novel approach to modeling change-points within the dynamic linear model framework.
The problem of modeling the change in a parameter value is similar to that of estimating sparse parameters, when the number of parameters is large relative to the number of data points.
That problem is relatively well studied, and there is a growing literature on Bayesian shrinkage priors.
This paper adopts one of this distributions, the Horseshoe Prior (Carvallho) et al. 

\section{Sparse Dynamic Linear Model}

Consider a simple local level model in which the mean of $y_{t}$ changes over time,
\begin{align}
  \label{eq:8}
  y_t &= \alpha_t + \epsilon_t \\
  \alpha_t &= \alpha_{t-1} + \eta_{t} \\
  \epsilon_{t} &\sim N(0, h^{2}) \\
  \eta_{t} &\sim N(0, q_{t}^{2})
\end{align}
The innovations $q_{t}$ are given a hierarchical prior,
\begin{align}
  \label{eq:4}
  \lambda^{}
\end{align}
This is known as the horseshoe density \textcite{CarvalhoPolsonScott2009}{CarvalhoPolsonScott2010}{DattaGhosh2012}.


\section{Time Varying Parameter Models}
\label{sec:time-vary-param}

% A dynamic linear model (DLM) is defined by the following set of equations \parencites{WestHarrison1997}{CommandeurKoopman2007},
% \begin{equation}
%   \label{eq:9}
%   \begin{aligned}[t]
%     y_{t} &= F \theta_{t} + \nu_{t} \\
%     \theta_{t} &= G \theta_{t - 1} + \omega_{t} 
%   \end{aligned}
% \end{equation}
% where $E(\nu_{t}) = 0$, $E(\omega_{t}) = 0$, and an initial prior distribution for $\theta_{0}$.
% This represents a general class of models that includes linear regression (with constant or time-varying parameters) as well as standard ARIMA time-series models.
% There are also computationally efficient methods to maximize (Kalman Filter) and sample from (Forward-Filter Backward Sample) DLMs if $\nu$ and $\omega$ are distributed normal.

Consider a simple local level model in which the mean of $y_{t}$ changes over time,
\begin{equation}
  \label{eq:8}
    y_t &= \alpha_t + \epsilon_t \\
    \alpha_t &= \alpha_{t-1} + \eta_{t}
\end{equation}
where $\epsilon_{t} \sim N(0, h_{t}^{2})$ and $\eta_{t} \sim N(0, q_{t}^{2})$.
This is a special case of a normal dynamic linear models (DLM) \parencite{WestHarrison1997}{DurbinKoopman2012}{CommandeurKoopman2007}{ShumwayStoffer2010}.
DLMs are flexible class of models that include linear regressions and ARIMA models.
Moreover for the case in which $\epsilon$ and $\eta$ are normal, there are computationally efficient methods both to maximize the likelihood of (Kalman Filter) and to sample from (Forward-filter backward samples) \eqref{eq:8}.

Commonly, $\eta_{t}$ are distributed i.i.d. normal,
\begin{equation}
  \label{eq:2}
  \eta_{t} \sim N(0, q^{2})
\end{equation}
Since the normal distribution has thin tails, \eqref{eq:2} smooths changes in $\alpha$ over time by penalizing large values of $\alpha_{t} - \alpha_{t-1}$.
Moreover, this means that $\alpha_{t} - \alpha_{t-1} \neq 0$ with certainty.
This is useful for modeling parameters which vary slowly over time.
However, many political processes are marked by sudden changes over time.

A structural break or change-point model can be represented in \eqref{eq:8} if $\eta$ is given a spike-and-slab mixture distribution \parencite{GiordaniKohn2008},
\begin{equation}
  \label{eq:1}
  \eta_{t} \sim p g(\eta_{t}) + (1 - p) \delta_{0} \text{,}
\end{equation}
where $p$ is the prior probability of a change, $g(\omega_{t})$ is the distribution of the change in $\alpha$ if there is a change-point.

There are several reasons why structural break methods are used.
The first is that the underlying data generating processes in political processes is often marked by large shifts.
The second is that stuctural breaks are easy to intrepret substantively.
The output of the methods provides a small number of breaks which can be interpreted with respect to the events occuring contemporaneously.

The key aspect of the a change point model is the sparsity in $\eta$.

A alternative approach is to model $\omega$ with a scale mixture of normal distributions.
\begin{equation}
  \label{eq:6}
  \begin{aligned}[t]
    \omega_{t} | \tau^{2}, \lambda^{2} & \sim N(0, \tau^{2} \lambda_{t}^{2}) \\
    \lambda_{t}^{2} & \sim p(\lambda^{2}_{t})
  \end{aligned}
\end{equation}
where $\tau^{2}$ is a global shrinkage parameter, and $\lambda_{t}^{2}$ are global shrinkage parameters.
Many Bayesian shrinkage priors can be expressed in this form. 

The class of scale-normal mixtures includes many of the suggested Bayesian shrinkage priors.

The $t$-distribution has suggested for dynamic linear model estimation that is robust to structural breaks.

This paper will focus on one particular shrinkage prior, the Horseshoe Prior distribution.

The Horseshoe prior distribution has several characteristics which make it particularly appealing for this problem.

This distribution has several characteristics that are useful.

\begin{equation}
  \label{eq:10}
  E(\omega_{t} | y_{t}, \theta_{t-1}, \lambda_{t}, \tau, \sigma^{2}) =
  \left(
    1 - \frac{1}{1 + \lambda_{t}^{2} \tau^{2}}
  \right) (y_{t} - \theta_{t - 1})
\end{equation}
For large $\psi^{2}$, the posterior mean $\hat\omega_{t}$ under the mixture innovation model is 
approximately $p_{t} (y_{t} - \theta_{t-1})$, where $p_{t}$ is the posterior probability that $\omega_{t} \neq 0$.
In the horseshoe estimator the quantity $\hat \omega_{t} = (1 - \hat \kappa) (y_{i} - \theta_{t})$.
The shrinkage weight behaves similarly to the posterior structural break probability $p_{t}$.
Because of this similarity, Carvalho proposes a simple decision rule under a symmetric 0-1 loss function
to identify signals, which in this case will be structural breaks,
\begin{equation}
  \label{eq:11}
  \text{Reject $H_{0t}$ if $p_{t} = 1 - E(\kappa_{t} | y_{t}, \theta_{t-1}, \tau, \omega^{2})$} > \frac{1}{2}
\end{equation}

\section{Examples}
\label{sec:examples}

\subsection{Nile Flow Data}
\label{sec:nile}

The first example of change-point detection is a classic datset in the state-space and change point literature, the Nile river flow data \textcite{Cobb1978}{Balke1993}{DurbinKoopman2012}
The data consist of annual observations of the flow of the Nile river at Ashwan between 1871 and 1970. 
It is well known that there was a level shift in 1899, both due to the construction of a damn at Ashwan and weather changes.

\subsection{Greenbacks}
\label{sec:greenbacks-graybacks}

\subsection{Election}
\label{sec:election}

Consider the ``Bush'' problem, estimating structural breaks in
presidential approval data. This is the example used in
\textcite{RatkovicEng2010}.

\printbibliography{}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

%  LocalWords:  Carvallho
